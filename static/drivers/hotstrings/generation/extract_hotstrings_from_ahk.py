#!/usr/bin/env python3
"""
Script to extract text expansion blocks from an AutoHotkey file
and convert them to TOML format.
"""

import re
import sys
import unicodedata
from pathlib import Path
from typing import Optional

sys.path.append(str(Path(__file__).resolve().parent.parent.parent))

from utilities.logger import get_error_count, logger, reset_error_count

# Common header for generated TOML files
TOML_HEADER = [
    "# DO NOT EDIT THIS FILE DIRECTLY.",
    "# This file is automatically generated. Any manual changes will be overwritten.",
    '# All entries use: trigger = { output = "replacement", is_word = true/false, auto_expand = true/false }',
    "",
]


def normalize_section_name(name: str) -> str:
    """
    Normalize section name by removing accents and converting to TOML-compatible format.

    Args:
        name: The original section name

    Returns:
        Normalized section name without accents and special characters
    """
    # Convert to lowercase
    name = name.lower()

    # Remove accents using unicodedata
    name = unicodedata.normalize("NFD", name)
    name = "".join(char for char in name if unicodedata.category(char) != "Mn")

    # Replace non-alphanumeric characters with underscores
    name = re.sub(r"[^a-z0-9_]", "_", name)

    # Remove multiple underscores and strip leading/trailing underscores
    name = re.sub(r"_+", "_", name).strip("_")

    return name


def deduplicate_hotstrings(
    hotstrings: dict[str, list[tuple[str, str, bool, bool, bool]]],
) -> dict[str, list[tuple[str, str, bool, bool, bool]]]:
    """
    Remove duplicate triggers within each section, keeping only the first occurrence.

    Args:
        hotstrings: Dictionary mapping section names to lists of (trigger, output, is_word, auto_expand) tuples

    Returns:
        Dictionary with duplicates removed, maintaining the order of first occurrences
    """
    deduplicated: dict[str, list[tuple[str, str, bool, bool, bool]]] = {}

    for section_name, entries in hotstrings.items():
        seen_triggers: set[str] = set()
        unique_entries: list[tuple[str, str, bool, bool]] = []

        for trigger, output, is_word, auto_expand, case_sensitive in entries:
            if trigger not in seen_triggers:
                seen_triggers.add(trigger)
                unique_entries.append(
                    (trigger, output, is_word, auto_expand, case_sensitive)
                )
            else:
                logger.debug(
                    "Skipping duplicate trigger '%s' in section '%s'",
                    trigger,
                    section_name,
                )

        deduplicated[section_name] = unique_entries

        # Log deduplication stats if any duplicates were found
        duplicates_removed = len(entries) - len(unique_entries)
        if duplicates_removed > 0:
            logger.info(
                "Removed %d duplicate trigger(s) from section '%s'",
                duplicates_removed,
                section_name,
            )

    return deduplicated


def main(ahk_file_path: Optional[Path] = None) -> None:
    """
    Main function to extract text expansion blocks from AutoHotkey files to TOML format.

    Args:
        ahk_file_path: Optional path to the AHK file. If None, automatically detects the latest version.
    """
    reset_error_count()

    # Determine source AHK file
    if ahk_file_path:
        source_file = Path(ahk_file_path).resolve()
    else:
        source_file = get_latest_ahk_file()

    if not source_file.exists():
        logger.error("Source AHK file does not exist: %s", source_file)
        return

    logger.info("=" * 80)
    logger.info("ðŸ“„ AutoHotkey to TOML Extraction")
    logger.info("=" * 80)
    logger.info("Source file: %s", source_file)

    # Define extraction tasks with support for multiple blocks per file
    # Format: {output_filename: [list_of_block_patterns]}
    # Each block pattern is a tuple: (category, block_name)
    # Order in this list matters for the deduplication process
    extractions = {
        "rolls": ["Rolls"],  # Special case: extract all Rolls blocks
        "qu": [("DistancesReduction", "QU")],
        "comma": [
            ("SFBsReduction", "Comma"),
            ("DistancesReduction", "CommaJ"),
            ("DistancesReduction", "CommaFarLetters"),
        ],
        # All SFBsReduction blocks are aggregated into a single output file
        # (see 'sfbreduction' below). Remove the older separate grouping.
        # New: extract all blocks under the SFBsReduction category into a dedicated file
        "sfb_reduction": ["SFBsReduction"],
        "suffixes": [("DistancesReduction", "SuffixesA")],
        "magic": [("MagicKey", "TextExpansion")],
        "accents": [("Autocorrection", "Accents")],
        "names": [("Autocorrection", "Names")],
        "brands": [("Autocorrection", "Brands")],
        "minus": [("Autocorrection", "Minus")],
        "punctuation": [("Autocorrection", "MultiplePunctuationMarks")],
        "errors": [("Autocorrection", "Errors")],
        # "apostrophe": [("Autocorrection", "TypographicApostrophe")], # Doesnâ€™t work well like in ahk
        "emojis": [("MagicKey", "TextExpansionEmojis")],
        "symbols": [("MagicKey", "TextExpansionSymbols")],
        "symbols_typst": [("MagicKey", "TextExpansionSymbolsTypst")],
    }

    processed = 0
    errors = 0

    # Define which files should go in the "plus" subfolder
    plus_files = {
        "apostrophe",
        "comma",
        "e_deadkey",
        "qu",
        "rolls",
        "sfbreduction",
        "suffixes",
    }

    # Set to track all triggers already written
    global_seen_triggers: set[str] = set()

    for output_name, block_patterns in extractions.items():
        logger.launch(
            "Extracting blocks %s to '%s.toml'", block_patterns, output_name
        )
        try:
            # Determine subfolder based on output name
            subfolder = "plus" if output_name in plus_files else ""

            # Patch: extract blocks, filter triggers already seen
            # Use extract_multiple_ahk_blocks_to_toml to get merged_hotstrings, but intercept before TOML write
            # Copy-paste logic from extract_multiple_ahk_blocks_to_toml, mais indentation corrigÃ©e
            # --- Begin extraction logic ---
            # Determine output file path (root hotstrings directory)
            generation_dir = Path(__file__).parent
            hotstrings_root = generation_dir.parent  # Move up from generation/
            output_dir = hotstrings_root / (subfolder if subfolder else "")
            output_dir.mkdir(exist_ok=True)
            output_file = output_dir / f"{output_name}.toml"

            # Read the AutoHotkey file
            try:
                with open(str(source_file), "r", encoding="utf-8") as f:
                    content = f.read()
            except FileNotFoundError:
                raise FileNotFoundError(f"Source file not found: {source_file}")
            except OSError as e:
                raise OSError(f"Error reading file {source_file}: {e}")

            # Extract and merge hotstrings from all specified blocks
            merged_hotstrings: dict[str, list[tuple[str, str, bool, bool]]] = {}
            found_blocks = []

            for block_pattern in block_patterns:
                # Handle special case where block_pattern is a category string (e.g., "Rolls")
                if isinstance(block_pattern, str):
                    block_content = extract_all_blocks_from_category(
                        content, block_pattern
                    )
                else:
                    block_content = extract_block_content(
                        content, block_pattern
                    )

                if block_content:
                    found_blocks.append(block_pattern)
                    hotstrings = extract_hotstrings(block_content)

                    # Merge hotstrings from this block
                    for section_name, entries in hotstrings.items():
                        # Create a unique section name to avoid conflicts
                        if len(block_patterns) > 1:
                            if isinstance(block_pattern, tuple):
                                category, block_name = block_pattern
                                unique_section_name = f"{normalize_section_name(block_name)}_{section_name}"
                            else:
                                unique_section_name = f"{normalize_section_name(block_pattern)}_{section_name}"
                        else:
                            unique_section_name = section_name

                        if unique_section_name not in merged_hotstrings:
                            merged_hotstrings[unique_section_name] = []
                        merged_hotstrings[unique_section_name].extend(entries)
                else:
                    logger.warning(
                        "Block '%s' not found in %s", block_pattern, source_file
                    )

            if not found_blocks:
                raise ValueError(
                    f"None of the blocks {block_patterns} found in {source_file}"
                )

            if not merged_hotstrings:
                logger.warning(
                    "No hotstrings found in blocks %s", block_patterns
                )

            # Fallback: sometimes some CreateCaseSensitiveHotstrings/Hotstring
            # calls are not captured by block-based extraction (e.g. blocks
            # without .Enabled or unusual formatting). For the 'sfbreduction'
            # aggregate we scan the whole AHK content for any remaining
            # Create*Hotstring calls and add them if missing.
            if output_name == "sfbreduction":
                # Fallback: limit the scan to SFBsReduction blocks only so we don't
                # accidentally capture hotstrings from other categories (e.g. SuffixesA).
                sfb_content = extract_all_blocks_from_category(
                    content, "SFBsReduction"
                )
                if sfb_content:
                    all_calls = re.finditer(
                        r"(?:CreateCaseSensitiveHotstrings|CreateHotstring|Hotstring)\s*\(.*?\)",
                        sfb_content,
                        re.DOTALL,
                    )
                    added = 0
                    for call in all_calls:
                        line_call = call.group(0)
                        trig, outp, is_w, auto_e, case_s = (
                            extract_hotstring_from_line(line_call)
                        )
                        # If parsing failed, try a simpler quoted-args fallback
                        if not trig or not outp:
                            # capture quoted string literals inside the call
                            q = re.findall(r'"((?:[^"\\]|\\.)*)"', line_call)
                            if len(q) >= 3:
                                options = q[0]
                                trig = process_autohotkey_escapes(q[1])
                                outp = process_autohotkey_escapes(q[2])
                                auto_e = "*" in options
                                is_w = "?" not in options
                                # keep case_s as previously-detected default
                                case_s = case_s

                        if trig and outp:
                            # check if already present
                            exists = False
                            for entries in merged_hotstrings.values():
                                for t, *_ in entries:
                                    if t == trig:
                                        exists = True
                                        break
                                if exists:
                                    break
                            if not exists:
                                if "general" not in merged_hotstrings:
                                    merged_hotstrings["general"] = []
                                merged_hotstrings["general"].append(
                                    (trig, outp, is_w, auto_e, case_s)
                                )
                                added += 1
                                logger.info(
                                    "Fallback: added trigger '%s' to sfbreduction",
                                    trig,
                                )
                    if added > 0:
                        logger.info(
                            "Fallback added %d missing sfbreduction hotstring(s)",
                            added,
                        )

            # Add hardcoded entries if this is the 'rolls' file
            if output_name == "rolls":
                hardcoded_entries = [
                    ("(#", '("', False, True, False),
                    ("[#", '["', False, True, False),
                    ("<%", "<=", False, True, False),
                    (">%", ">=", False, True, False),
                ]
                if "general" not in merged_hotstrings:
                    merged_hotstrings["general"] = []
                merged_hotstrings["general"].extend(hardcoded_entries)

            # Remove duplicates: keep only the first occurrence of each trigger within each section
            deduplicated_hotstrings = deduplicate_hotstrings(merged_hotstrings)

            # --- Patch: filter triggers already seen globally ---
            filtered_hotstrings: dict[
                str, list[tuple[str, str, bool, bool, bool]]
            ] = {}
            for section_name, entries in deduplicated_hotstrings.items():
                filtered_entries = []
                for (
                    trigger,
                    output,
                    is_word,
                    auto_expand,
                    case_sensitive,
                ) in entries:
                    # Always include emoji triggers (emojis file) to avoid them being
                    # filtered by earlier files. For other files, keep global dedupe.
                    if (
                        output_name == "emojis"
                        or trigger not in global_seen_triggers
                    ):
                        global_seen_triggers.add(trigger)
                        filtered_entries.append(
                            (
                                trigger,
                                output,
                                is_word,
                                auto_expand,
                                case_sensitive,
                            )
                        )
                    else:
                        logger.info(
                            "Skipping duplicate trigger '%s' (already present in previous file)",
                            trigger,
                        )
                if filtered_entries:
                    filtered_hotstrings[section_name] = filtered_entries

            # Convert to TOML format using the first found block as block_name for compatibility
            first_block = found_blocks[0]
            if isinstance(first_block, tuple):
                block_name_for_toml = first_block[1]  # Use the block name part
            else:
                block_name_for_toml = first_block

            # Try to extract a menu description for the primary block and include it in the TOML header
            menu_desc = None
            try:
                menu_desc = find_description_in_content(
                    content, block_name_for_toml
                )
            except Exception:
                menu_desc = None

            descriptions_param = (
                {block_name_for_toml: menu_desc} if menu_desc else None
            )

            toml_content = convert_to_toml(
                filtered_hotstrings, block_name_for_toml, descriptions_param
            )

            # Write the TOML file
            try:
                with open(output_file, "w", encoding="utf-8") as f:
                    f.write(toml_content)

                total_entries = sum(
                    len(entries) for entries in filtered_hotstrings.values()
                )
                logger.info(
                    "TOML file created: %s (%d entries from %d blocks: %s)",
                    output_file.name,
                    total_entries,
                    len(found_blocks),
                    found_blocks,
                )

            except OSError as e:
                raise OSError(f"Error writing file {output_file}: {e}")
            # --- End extraction logic ---
            processed += 1
            logger.info(
                "Successfully extracted blocks %s to '%s.toml'",
                block_patterns,
                output_name,
            )
        except (OSError, ValueError, RuntimeError) as e:
            logger.error("Error extracting blocks %s: %s", block_patterns, e)
            errors += 1

    show_execution_summary(processed, errors)

    #


def extract_multiple_ahk_blocks_to_toml(
    ahk_file_path: str,
    block_patterns: list[tuple[str, str] | str],
    output_name: str,
    subfolder: str = "",
) -> None:
    """
    Extract multiple blocks from an AutoHotkey file and merge them into a single TOML file.

    Args:
        ahk_file_path: Path to the source .ahk file
        block_patterns: List of block patterns to extract. Can be tuples (category, block_name)
                       or strings (category) for extracting all blocks from a category
        output_name: Output filename without extension (e.g., 'comma')
        subfolder: Optional subfolder name for organizing output files

    Raises:
        FileNotFoundError: If the source file doesn't exist
        ValueError: If none of the block patterns are found
        OSError: If there's an error writing the output file
    """
    # Determine output file path (root hotstrings directory)
    generation_dir = Path(__file__).parent
    hotstrings_root = generation_dir.parent  # Move up from generation/
    output_dir = hotstrings_root / (subfolder if subfolder else "")
    output_dir.mkdir(exist_ok=True)
    output_file = output_dir / f"{output_name}.toml"

    # Read the AutoHotkey file
    try:
        with open(ahk_file_path, "r", encoding="utf-8") as f:
            content = f.read()
    except FileNotFoundError:
        raise FileNotFoundError(f"Source file not found: {ahk_file_path}")
    except OSError as e:
        raise OSError(f"Error reading file {ahk_file_path}: {e}")

    # Extract and merge hotstrings from all specified blocks
    merged_hotstrings: dict[str, list[tuple[str, str, bool, bool, bool]]] = {}
    found_blocks = []

    for block_pattern in block_patterns:
        # Handle special case where block_pattern is a category string (e.g., "Rolls")
        if isinstance(block_pattern, str):
            block_content = extract_all_blocks_from_category(
                content, block_pattern
            )
        else:
            block_content = extract_block_content(content, block_pattern)

        if block_content:
            found_blocks.append(block_pattern)
            hotstrings = extract_hotstrings(block_content)

            # Merge hotstrings from this block
            for section_name, entries in hotstrings.items():
                # Create a unique section name to avoid conflicts
                if len(block_patterns) > 1:
                    if isinstance(block_pattern, tuple):
                        category, block_name = block_pattern
                        unique_section_name = f"{normalize_section_name(block_name)}_{section_name}"
                    else:
                        unique_section_name = f"{normalize_section_name(block_pattern)}_{section_name}"
                else:
                    unique_section_name = section_name

                if unique_section_name not in merged_hotstrings:
                    merged_hotstrings[unique_section_name] = []
                merged_hotstrings[unique_section_name].extend(entries)
        else:
            logger.warning(
                "Block '%s' not found in %s", block_pattern, ahk_file_path
            )

    if not found_blocks:
        raise ValueError(
            f"None of the blocks {block_patterns} found in {ahk_file_path}"
        )

    if not merged_hotstrings:
        logger.warning("No hotstrings found in blocks %s", block_patterns)

    # Add hardcoded entries if this is the 'rolls' file
    if output_name == "rolls":
        hardcoded_entries = [
            ("(#", '("', False, True),
            ("[#", '["', False, True),
            ("<%", "<=", False, True),
            (">%", ">=", False, True),
        ]
        if "general" not in merged_hotstrings:
            merged_hotstrings["general"] = []
        merged_hotstrings["general"].extend(hardcoded_entries)

    # Remove duplicates: keep only the first occurrence of each trigger within each section
    deduplicated_hotstrings = deduplicate_hotstrings(merged_hotstrings)

    # Convert to TOML format using the first found block as block_name for compatibility
    first_block = found_blocks[0]
    if isinstance(first_block, tuple):
        block_name_for_toml = first_block[1]  # Use the block name part
    else:
        block_name_for_toml = first_block

    # Collect descriptions for each block pattern found (use block names as in AHK)
    descriptions: dict[str, str] = {}
    for bp in found_blocks:
        if isinstance(bp, tuple):
            _, block_name = bp
        else:
            block_name = bp
        desc = find_description_in_content(content, block_name)
        if desc:
            descriptions[block_name] = desc

    toml_content = convert_to_toml(
        deduplicated_hotstrings,
        block_name_for_toml,
        descriptions if descriptions else None,
    )

    # Write the TOML file
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(toml_content)

        total_entries = sum(
            len(entries) for entries in merged_hotstrings.values()
        )
        logger.info(
            "TOML file created: %s (%d entries from %d blocks: %s)",
            output_file.name,
            total_entries,
            len(found_blocks),
            found_blocks,
        )

    except OSError as e:
        raise OSError(f"Error writing file {output_file}: {e}")


def get_latest_ahk_file() -> Path:
    """
    Automatically detect the latest AutoHotkey file version.

    Returns:
        Path to the latest AHK file.

    Raises:
        FileNotFoundError: If no AHK file is found.
    """
    ahk_directory = Path(__file__).parent.parent.parent / "autohotkey"

    # Look for files matching pattern ErgoptiPlus_v*.*.*.ahk
    ahk_files = list(ahk_directory.glob("ErgoptiPlus_v*.*.*.ahk"))

    if not ahk_files:
        raise FileNotFoundError(f"No AutoHotkey files found in {ahk_directory}")

    # Sort by version number and return the latest
    ahk_files.sort(key=lambda f: extract_version_tuple(f.name), reverse=True)
    latest_file = ahk_files[0]

    logger.info("Auto-detected latest AHK file: %s", latest_file.name)
    return latest_file


def extract_version_tuple(filename: str) -> tuple[int, int, int]:
    """
    Extract version tuple from filename for sorting.

    Args:
        filename: The filename containing version info.

    Returns:
        Tuple of (major, minor, patch) version numbers.
    """
    match = re.search(r"v(\d+)\.(\d+)\.(\d+)", filename)
    if match:
        return (int(match.group(1)), int(match.group(2)), int(match.group(3)))
    return (0, 0, 0)


def extract_ahk_block_to_toml(
    ahk_file_path: str, block_pattern: str, output_name: str
) -> None:
    """
    Extract a specific block from an AutoHotkey file and convert it to TOML format.

    Args:
        ahk_file_path: Path to the source .ahk file
        block_pattern: Pattern of the block to extract (e.g., 'TextExpansionEmojis')
        output_name: Output filename without extension (e.g., 'emojis')

    Raises:
        FileNotFoundError: If the source file doesn't exist
        ValueError: If the block pattern is not found
        OSError: If there's an error writing the output file
    """
    # Determine output file path (root hotstrings directory)
    generation_dir = Path(__file__).parent
    hotstrings_root = generation_dir.parent
    output_dir = hotstrings_root
    output_file = output_dir / f"{output_name}.toml"

    # Read the AutoHotkey file
    try:
        with open(ahk_file_path, "r", encoding="utf-8") as f:
            content = f.read()
    except FileNotFoundError:
        raise FileNotFoundError(f"Source file not found: {ahk_file_path}")
    except OSError as e:
        raise OSError(f"Error reading file {ahk_file_path}: {e}")

    # Extract block content using robust brace matching
    block_content = extract_block_content(content, block_pattern)

    if not block_content:
        raise ValueError(
            f"Block '{block_pattern}' not found in {ahk_file_path}"
        )

    # Extract hotstrings from block content
    hotstrings = extract_hotstrings(block_content)

    if not hotstrings:
        logger.warning("No hotstrings found in block '%s'", block_pattern)

    # Remove duplicates: keep only the first occurrence of each trigger within each section
    deduplicated_hotstrings = deduplicate_hotstrings(hotstrings)

    # Convert to TOML format
    # Try to extract description for this block from the source AHK content
    desc = find_description_in_content(content, block_pattern)
    descriptions = {block_pattern: desc} if desc else None
    toml_content = convert_to_toml(
        deduplicated_hotstrings, block_pattern, descriptions
    )

    # Write the TOML file
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(toml_content)

        total_entries = sum(
            len(entries) for entries in deduplicated_hotstrings.values()
        )
        logger.info(
            "TOML file created: %s (%d entries)",
            output_file.name,
            total_entries,
        )

    except OSError as e:
        raise OSError(f"Error writing file {output_file}: {e}")


def extract_block_content(
    content: str, block_pattern: tuple[str, str] | str
) -> str:
    """
    Extract block content using robust brace matching to handle nested braces.

    Args:
        content: The full AutoHotkey file content
        block_pattern: Either a tuple (category, block_name) for precise targeting,
                      or a string block_name for backward compatibility

    Returns:
        The extracted block content, or empty string if not found
    """
    if isinstance(block_pattern, tuple):
        category, block_name = block_pattern
        # Try both patterns: with and without .Enabled suffix
        # Accept additional boolean conditions before the opening brace (e.g. "and Features[...]...")
        start_pattern_enabled = rf'if Features\["{category}"\]\["{block_name}"\]\.Enabled\b[^{{]*\{{'
        start_pattern_simple = (
            rf'if Features\["{category}"\]\["{block_name}"\]\b[^{{]*\{{'
        )
    else:
        # Backward compatibility: general pattern to match any Features[...][block_pattern] block
        start_pattern_enabled = (
            rf'if Features\["[^"]+"\]\["{block_pattern}"\]\.Enabled\s*\{{'
        )
        start_pattern_simple = (
            rf'if Features\["[^"]+"\]\["{block_pattern}"\]\s*\{{'
        )

    # Try both patterns: first with .Enabled, then without
    start_match = re.search(start_pattern_enabled, content)
    if not start_match:
        start_match = re.search(start_pattern_simple, content)

    if not start_match:
        return ""

    # Find the matching closing brace using brace counting
    start_idx = start_match.end()
    brace_count = 1
    end_idx = start_idx

    while end_idx < len(content) and brace_count > 0:
        if content[end_idx] == "{":
            brace_count += 1
        elif content[end_idx] == "}":
            brace_count -= 1
        end_idx += 1

    return content[start_idx : end_idx - 1] if brace_count == 0 else ""


def extract_all_blocks_from_category(content: str, category: str) -> str:
    """
    Extract all blocks from a specific category and merge their content.

    Args:
        content: The full AutoHotkey file content
        category: The category name (e.g., "Rolls")

    Returns:
        The merged content of all blocks in the category
    """
    # Find all Features["category"]["..."] blocks (with or without .Enabled)
    # Accept additional boolean conditions before the opening brace (e.g. "and Features[...]...")
    pattern_enabled = (
        rf'if Features\["{category}"\]\["[^\"]+"\]\.Enabled\b[^{{]*\{{'
    )
    pattern_simple = rf'if Features\["{category}"\]\["[^\"]+"\]\b[^{{]*\{{'

    matches = list(re.finditer(pattern_enabled, content))
    matches.extend(re.finditer(pattern_simple, content))

    if not matches:
        return ""

    merged_content = []

    for match in matches:
        # Find the matching closing brace using brace counting
        start_idx = match.end()
        brace_count = 1
        end_idx = start_idx

        while end_idx < len(content) and brace_count > 0:
            if content[end_idx] == "{":
                brace_count += 1
            elif content[end_idx] == "}":
                brace_count -= 1
            end_idx += 1

        if brace_count == 0:
            block_content = content[start_idx : end_idx - 1]
            merged_content.append(block_content)

    return "\n".join(merged_content)


def find_description_in_content(content: str, section_name: str) -> str:
    """
    Find a Description value for a given section/block name inside the Features map.

    Returns the unescaped description string, or empty string if not found.
    """
    # Search for the block definition like: "SectionName", { ... Description: "...",
    pattern = rf'"{re.escape(section_name)}"\s*,\s*\{{'
    m = re.search(pattern, content)
    if not m:
        return ""

    # Find matching closing brace for this block definition
    start_idx = m.end()
    brace_count = 1
    end_idx = start_idx
    while end_idx < len(content) and brace_count > 0:
        if content[end_idx] == "{":
            brace_count += 1
        elif content[end_idx] == "}":
            brace_count -= 1
        end_idx += 1

    block_text = content[start_idx : end_idx - 1] if brace_count == 0 else ""
    if not block_text:
        return ""

    # Accept AHK-escaped quotes like `" inside the Description string
    # More robust: after 'Description', concatenate all adjacent quoted string literals
    # Example handled: Description: "A " . ScriptInformation[...] . " B",
    m = re.search(r"Description\s*:\s*", block_text)
    if not m:
        return ""
    idx = m.end()
    length = len(block_text)
    parts: list[str] = []
    in_literal = False
    # Scan forward collecting double-quoted string literals
    while idx < length:
        ch = block_text[idx]
        if ch.isspace() or ch == ".":
            idx += 1
            continue
        if ch == '"':
            # parse quoted string supporting AHK `" escapes and doubled quotes
            idx += 1
            start = idx
            literal_chars: list[str] = []
            while idx < length:
                c = block_text[idx]
                # handle backtick-escaped quote
                if c == "`" and idx + 1 < length and block_text[idx + 1] == '"':
                    literal_chars.append('"')
                    idx += 2
                    continue
                if c == '"':
                    idx += 1
                    break
                literal_chars.append(c)
                idx += 1
            parts.append(process_autohotkey_escapes("".join(literal_chars)))
            # after closing quote, continue to look for more literals or stop at comma
            # skip spaces
            while idx < length and block_text[idx].isspace():
                idx += 1
            if idx < length and block_text[idx] == ",":
                break
            continue
        # if we hit a comma before any literal, stop
        if ch == ",":
            break
        # otherwise skip non-literal tokens (variables, concatenation, etc.)
        # try to capture ScriptInformation["Key"] and insert the key name
        rem = block_text[idx:]
        si = re.match(
            r"\s*\.\s*ScriptInformation\s*\[\s*\"([^\"]+)\"\s*\]", rem
        )
        if not si:
            si = re.match(r"\s*ScriptInformation\s*\[\s*\"([^\"]+)\"\s*\]", rem)
        if si:
            # replace ScriptInformation[...] occurrences by the MagicKey symbol
            # place the star without a leading space to avoid double spacing
            parts.append("â˜… ")
            idx += si.end()
            continue
        idx += 1

    return "".join(parts)


def extract_hotstrings(
    block_content: str,
) -> dict[str, list[tuple[str, str, bool, bool]]]:
    """
    Extract hotstrings from an AutoHotkey block content.

    Args:
        block_content: The AutoHotkey block content to parse

    Returns:
        Dictionary mapping section names to lists of (trigger, output, is_word, auto_expand) tuples
    """
    hotstrings: dict[str, list[tuple[str, str, bool, bool, bool]]] = {}
    current_section = "general"

    lines = block_content.split("\n")
    i = 0

    while i < len(lines):
        line = lines[i].strip()

        # Detect section headers (comments === Section ===)
        section_match = re.match(r";\s*===\s*(.+?)\s*===", line)
        if section_match:
            section_name = section_match.group(1)
            # Normalize section name for TOML compatibility (removes accents and special chars)
            current_section = normalize_section_name(section_name)
            if current_section not in hotstrings:
                hotstrings[current_section] = []
            i += 1
            continue

        # Skip comments and empty lines
        if line.startswith(";") or not line:
            i += 1
            continue

        # Check if this is the start of a multi-line CreateCaseSensitiveHotstrings or CreateHotstring call
        is_multiline = False
        if (
            (
                "CreateCaseSensitiveHotstrings(" in line
                or "CreateHotstring(" in line
            )
            and not line.rstrip().endswith(")")
            and not line.split(";")[0].rstrip().endswith(")")
        ):
            # Collect multi-line statement
            full_line = line
            j = i + 1
            while (
                j < len(lines)
                and not full_line.rstrip().endswith(")")
                and not full_line.split(";")[0].rstrip().endswith(")")
            ):
                full_line += " " + lines[j].strip()
                j += 1
            i = j  # Skip processed lines
            line = full_line
            is_multiline = True

        # Extract hotstrings using multiple patterns to cover all cases
        trigger, output, is_word, auto_expand, case_sensitive = (
            extract_hotstring_from_line(line)
        )
        if trigger and output:
            # Initialize section if it doesn't exist
            if current_section not in hotstrings:
                hotstrings[current_section] = []
            hotstrings[current_section].append(
                (trigger, output, is_word, auto_expand, case_sensitive)
            )
            logger.debug(
                "Extracted: section='%s', trigger='%s', output='%s'",
                current_section,
                trigger,
                output,
            )
        else:
            # Log lines that weren't extracted
            if (
                "CreateCaseSensitiveHotstrings(" in line
                or "CreateHotstring(" in line
                or "Hotstring" in line
            ):
                logger.warning(
                    "Failed to extract from line: %s",
                    line[:100] + "..." if len(line) > 100 else line,
                )

        # Move to next line (only if we didn't already do it in multi-line processing)
        if not is_multiline:
            i += 1

    return hotstrings


def process_autohotkey_escapes(text: str) -> str:
    """
    Process AutoHotkey escape sequences in text.

    Args:
        text: The text containing AutoHotkey escape sequences

    Returns:
        Text with escape sequences converted to actual characters
    """
    # Convert `" to "
    text = text.replace('`"', '"')
    # Convert `' to '
    text = text.replace("`'", "'")
    # Convert `` to `
    text = text.replace("``", "`")
    # Convert `n to newline
    text = text.replace("`n", "\n")
    # Convert `t to tab
    text = text.replace("`t", "\t")
    # Convert `r to carriage return
    text = text.replace("`r", "\r")
    # Convert `{ and `} to { and }
    text = text.replace("`{", "{")
    text = text.replace("`}", "}")

    # Remove AutoHotkey specific cursor positioning sequences
    # Handle patterns like \"\"{Left} -> \"
    text = text.replace('""{Left}', '"')
    text = text.replace('"{Left}', "")
    text = text.replace("{Left}", "")
    text = text.replace("{Right}", "")
    text = text.replace("{Up}", "")
    text = text.replace("{Down}", "")
    text = text.replace("{Home}", "")
    text = text.replace("{End}", "")

    return text


def process_complex_output_expression(output_expr: str) -> Optional[str]:
    """
    Process complex AutoHotkey output expressions that include variable concatenation.

    Args:
        output_expr: The AutoHotkey output expression to process

    Returns:
        The processed output string, or None if it cannot be processed
    """
    # Remove surrounding quotes if present
    output_expr = output_expr.strip()
    if output_expr.startswith('"') and output_expr.endswith('"'):
        return process_autohotkey_escapes(output_expr[1:-1])

    # Handle common variable concatenations
    space_around_symbols = " "  # Default value for SpaceAroundSymbols

    # Simple string literals
    if output_expr.startswith('"') and output_expr.endswith('"'):
        return process_autohotkey_escapes(output_expr[1:-1])

    # Handle concatenation with SpaceAroundSymbols
    if "SpaceAroundSymbols" in output_expr:
        # Replace SpaceAroundSymbols with space and evaluate concatenation
        parts = output_expr.split(".")
        result = ""

        for part in parts:
            part = part.strip()
            if part == "SpaceAroundSymbols":
                result += space_around_symbols
            elif part.startswith('"') and part.endswith('"'):
                result += process_autohotkey_escapes(part[1:-1])
            elif part in (
                '":="',
                '"!="',
                '"="',
                '"=>"',
                '"<="',
                '"->"',
                '"<-"',
                '"âžœ"',
            ):
                result += part[1:-1]  # Remove surrounding quotes
            elif part == '"`"`"{Left}"':
                result += '""'  # Simplified for TOML output
            # Skip unknown variables or complex expressions

        return result if result else None

    # Handle other simple quoted strings
    quote_match = re.search(r'^"([^"]*)"$', output_expr)
    if quote_match:
        result = process_autohotkey_escapes(quote_match.group(1))
        # Remove AutoHotkey specific cursor positioning
        result = result.replace("{Left}", "")
        result = result.replace("{Right}", "")
        result = result.replace("{Up}", "")
        result = result.replace("{Down}", "")
        result = result.replace("{Home}", "")
        result = result.replace("{End}", "")
        return result

    # If we can't process it, log and return None
    logger.debug("Cannot process complex output expression: %s", output_expr)
    return None


def extract_hotstring_from_line(
    line: str,
) -> tuple[Optional[str], Optional[str], bool, bool, bool]:
    """
    Extract trigger and output from a single AutoHotkey line.

    Args:
            line: The AutoHotkey line to parse

    Returns:
            Tuple of (trigger, output, is_word, auto_expand) or (None, None, False, False) if no match
    """
    # Detect case-sensitivity: CreateCaseSensitiveHotstrings implies case sensitive
    case_sensitive = "CreateCaseSensitiveHotstrings" in line

    # Pattern for CreateHotstring with complex escape sequences
    complex_escape_pattern = (
        r"CreateHotstring\s*\(\s*"
        r'"([^"]*)",\s*'  # Options group 1
        r'"([^"]+)",\s*'  # Trigger group 2 - simple capture
        r'"(`"[^"]*)"'  # Output group 3 - specifically for backtick-quote sequences like `") and `"]
        r".*?"  # Match anything after
        r"\)"
    )

    complex_escape_match = re.search(complex_escape_pattern, line, re.DOTALL)

    if complex_escape_match:
        options, trigger, output = complex_escape_match.groups()

        # Determine auto_expand and is_word based on options
        auto_expand = "*" in options
        is_word = "?" not in options

        # Handle special case where trigger contains ScriptInformation["MagicKey"]
        if 'ScriptInformation["MagicKey"]' in line:
            trigger += "â˜…"

        # Process both trigger and output through AutoHotkey escape processing
        trigger = process_autohotkey_escapes(trigger)
        output = process_autohotkey_escapes(output)

        logger.debug(
            "Found CreateHotstring (complex): trigger='%s', options='%s', auto_expand=%s, is_word=%s",
            trigger,
            options,
            auto_expand,
            is_word,
        )

        return trigger, output, is_word, auto_expand, case_sensitive

    # General pattern for CreateHotstring with escaped triggers
    general_escape_pattern = (
        r"CreateHotstring\s*\(\s*"
        r'"([^"]*)",\s*'  # Options group 1
        r'"((?:[^"\\]|\\.|"")*)",\s*'  # Trigger group 2 - handles \`" sequences and quotes
        r'"([^"]*)"'  # Output group 3 - simple output
        r".*?"  # Match anything after
        r"\)"
    )

    general_escape_match = re.search(general_escape_pattern, line, re.DOTALL)

    if general_escape_match:
        options, trigger, output = general_escape_match.groups()

        # Determine auto_expand and is_word based on options
        auto_expand = "*" in options
        is_word = "?" not in options

        # Handle special case where trigger contains ScriptInformation["MagicKey"]
        if 'ScriptInformation["MagicKey"]' in line:
            trigger += "â˜…"

        # Process both trigger and output through AutoHotkey escape processing
        trigger = process_autohotkey_escapes(trigger)
        output = process_autohotkey_escapes(output)

        logger.debug(
            "Found CreateHotstring (general): trigger='%s', options='%s', auto_expand=%s, is_word=%s",
            trigger,
            options,
            auto_expand,
            is_word,
        )

        return trigger, output, is_word, auto_expand, case_sensitive

    # Handle complex CreateHotstring lines with variable concatenation
    # Pattern for CreateHotstring with string concatenation in output
    complex_create_pattern = (
        r"CreateHotstring\s*\(\s*"
        r'"([^"]*)",\s*'  # Options group 1
        r'"([^"\\]*(?:\\.[^"\\]*)*)",\s*'  # Trigger group 2 - handles escaped chars
        r"([^,)]+),\s*"  # Output group 3 - can be complex expression with concatenation
        r".*?"  # Match anything after (Map parameters)
        r"\)"
    )

    complex_match = re.search(complex_create_pattern, line, re.DOTALL)

    if complex_match:
        options, trigger, output_expr = complex_match.groups()

        # Determine auto_expand and is_word based on options
        auto_expand = "*" in options
        is_word = "?" not in options

        # Handle special case where trigger contains ScriptInformation["MagicKey"]
        if 'ScriptInformation["MagicKey"]' in line:
            trigger += "â˜…"

        # Process trigger escapes
        trigger = process_autohotkey_escapes(trigger)

        # Process complex output expressions
        output = process_complex_output_expression(output_expr)

        if output:  # Only return if we successfully processed the output
            logger.debug(
                "Found CreateHotstring: trigger='%s', options='%s', auto_expand=%s, is_word=%s",
                trigger,
                options,
                auto_expand,
                is_word,
            )
            return trigger, output, is_word, auto_expand, case_sensitive

    # First, try to match simple CreateHotstring format
    # Updated regex to handle escaped quotes in both trigger and output
    create_hotstring_pattern = (
        r"CreateHotstring\s*\(\s*"
        r'"([^"]*)",\s*'  # Options group 1
        r'"((?:[^"]|""|`.)*?)"(?:\s*\.\s*ScriptInformation\["MagicKey"\])?,\s*'  # Trigger group 2
        r'"((?:[^"]|""|`.)*?)"'  # Output group 3
        r".*?"  # Match anything after the output (including Map parameters)
        r"\)"
    )

    create_hotstring_match = re.search(
        create_hotstring_pattern, line, re.DOTALL
    )

    if create_hotstring_match:
        options, trigger, output = create_hotstring_match.groups()

        # Determine auto_expand and is_word based on options
        auto_expand = "*" in options
        is_word = "?" not in options

        # Handle special case where trigger contains ScriptInformation["MagicKey"]
        if 'ScriptInformation["MagicKey"]' in line:
            trigger += "â˜…"

        # Process both trigger and output through AutoHotkey escape processing
        trigger = process_autohotkey_escapes(trigger)
        output = process_autohotkey_escapes(output)

        logger.debug(
            "Found CreateHotstring: trigger='%s', options='%s', auto_expand=%s, is_word=%s",
            trigger,
            options,
            auto_expand,
            is_word,
        )

        return trigger, output, is_word, auto_expand, case_sensitive

    # Second, try to match CreateCaseSensitiveHotstrings format
    create_pattern = (
        r"CreateCaseSensitiveHotstrings\s*\(\s*"
        r'"([^"]*)",\s*'  # Options group 1
        r'"([^"]+)"(?:\s*\.\s*ScriptInformation\["MagicKey"\])?,\s*'  # Trigger group 2 - handles concatenation with MagicKey
        r'"([^"]+)"'  # Output group 3
        r".*?"  # Match anything after the output (including Map parameters)
        r"\)"
    )

    create_match = re.search(create_pattern, line, re.DOTALL)

    if create_match:
        options, trigger, output = create_match.groups()

        # Determine auto_expand and is_word based on options
        auto_expand = "*" in options
        is_word = "?" not in options

        # Handle special case where trigger contains ScriptInformation["MagicKey"]
        if 'ScriptInformation["MagicKey"]' in line:
            trigger += "â˜…"

        # Process both trigger and output through AutoHotkey escape processing
        trigger = process_autohotkey_escapes(trigger)
        output = process_autohotkey_escapes(output)

        logger.debug(
            "Found CreateCaseSensitiveHotstrings: trigger='%s', options='%s', auto_expand=%s, is_word=%s",
            trigger,
            options,
            auto_expand,
            is_word,
        )

        return trigger, output, is_word, auto_expand, case_sensitive

    # Fallback to original Hotstring format
    hotstring_pattern = (
        r"Hotstring[s]?\s*\("
        r'(?:\s*"([^"]+)",)?'  # Optional options group 1
        r'\s*"([^"]+?)"'  # Trigger group 2
        r'(?:\s*\.\s*ScriptInformation\["MagicKey"\])?'
        r'\s*,\s*"([^"]+?)"'  # Output group 3
        r"\s*\)"
    )

    hotstring_match = re.search(hotstring_pattern, line, re.DOTALL)

    if hotstring_match:
        options, trigger, output = hotstring_match.groups()

        is_word = True  # Default to True, meaning it's a whole word trigger
        auto_expand = False  # Default for Hotstring format

        if options and "?" in options:
            is_word = False  # Set to False if it can be triggered inside a word

        if options and "*" in options:
            auto_expand = True

        if 'ScriptInformation["MagicKey"]' in line:
            trigger += "â˜…"

        # Process both trigger and output through AutoHotkey escape processing
        trigger = process_autohotkey_escapes(trigger)
        output = process_autohotkey_escapes(output)

        logger.debug(
            "Found Hotstring: trigger='%s', options='%s', auto_expand=%s, is_word=%s",
            trigger,
            options,
            auto_expand,
            is_word,
        )

        return trigger, output, is_word, auto_expand, case_sensitive
    return None, None, False, False, False


def convert_to_toml(
    hotstrings: dict[str, list[tuple[str, str, bool, bool, bool]]],
    block_name: str,
    descriptions: dict[str, str] | None = None,
) -> str:
    """
    Convert hotstrings dictionary to TOML format.

    Args:
        hotstrings: Dictionary mapping section names to lists of (trigger, output, is_word, auto_expand) tuples
        block_name: Name of the original block (used for header comment)

    Returns:
            Formatted TOML content as string
    """
    # Mutualized header for all TOML files
    header_lines = TOML_HEADER.copy()
    header_lines.insert(2, "# Format: [[section]]")  # Add section format info

    toml_lines = header_lines.copy()

    # If a menu/block description was provided for this file, add it as
    # structured metadata for easy programmatic retrieval.
    file_description = None
    if descriptions and block_name in descriptions:
        file_description = descriptions.pop(block_name)

    if file_description:
        toml_lines.append("[metadata]")
        toml_lines.append(f'block = "{escape_toml_string(block_name)}"')
        toml_lines.append(
            f'description = "{escape_toml_string(file_description)}"'
        )
        toml_lines.append("")

    # Main sections
    for section_name, entries in hotstrings.items():
        if not entries:
            continue
        toml_lines.append(f"[[{section_name}]]")
        # If we have a description for this precise section name, add it
        # inside the section table for structured retrieval.
        if descriptions and section_name in descriptions:
            sec_desc = descriptions[section_name].replace("\n", " ").strip()
            if sec_desc:
                toml_lines.append(
                    f'description = "{escape_toml_string(sec_desc)}"'
                )
        for trigger, output, is_word, auto_expand, case_sensitive in entries:
            # Always escape both trigger and output for valid TOML
            trigger_escaped = escape_toml_string(trigger)
            output_escaped = escape_toml_string(output)

            # Always use complex format for all entries
            toml_lines.append(
                f'"{trigger_escaped}" = {{ output = "{output_escaped}", is_word = {str(is_word).lower()}, auto_expand = {str(auto_expand).lower()}, is_case_sensitive = {str((not case_sensitive)).lower()} }}'
            )
        toml_lines.append("")

    return "\n".join(toml_lines)


def escape_toml_string(text: str) -> str:
    """
    Escape special characters in a string for TOML format.

    This function properly escapes backslashes first, then quotes to ensure
    correct TOML formatting. For example: \" becomes \\\"

    Args:
        text: The string to escape

    Returns:
        Escaped string suitable for TOML
    """
    # Important: escape backslashes first, then quotes
    # This ensures that \" becomes \\\" (not \\\")
    text = text.replace("\\", "\\\\")
    text = text.replace('"', '\\"')
    return text


def show_execution_summary(processed: int, errors: int) -> None:
    """
    Display a summary of the extraction process.

    Args:
        processed: Number of successfully processed blocks
        errors: Number of errors encountered
    """
    if errors == 0 and get_error_count() == 0:
        logger.success("=" * 83)
        logger.success("=" * 83)
        logger.success("=" * 83)
        logger.success(
            "======= All blocks processed successfully: %d block(s) processed, no errors! =======",
            processed,
        )
        logger.success("=" * 83)
        logger.success("=" * 83)
        logger.success("=" * 83)
    else:
        logger.error("=" * 100)
        logger.error("=" * 100)
        logger.error("=" * 100)
        logger.error(
            "======= Processing complete. %d block(s) processed, %d error(s) (exceptions), %d error log(s). =======",
            processed,
            errors,
            get_error_count(),
        )
        logger.error("=" * 100)
        logger.error("=" * 100)
        logger.error("=" * 100)


def generate_e_deadkey_toml(
    ahk_file_path: Optional[str] = None, subfolder: str = ""
) -> None:
    """
    Generate e_deadkey.toml file with Ãª + vowel = vowel with ^ mappings.
    Also includes content from ECirc block and Ãª + e = Å“.

    Args:
        ahk_file_path: Optional path to AHK file. If None, uses latest version.
        subfolder: Optional subfolder name for organizing output files
    """
    generation_dir = Path(__file__).parent
    hotstrings_root = generation_dir.parent
    output_dir = hotstrings_root / (subfolder if subfolder else "")
    output_dir.mkdir(exist_ok=True)
    output_file = output_dir / "e_deadkey.toml"

    # Define the basic deadkey mappings: Ãª + vowel = vowel with circumflex
    # Only include lowercase mappings to avoid duplicates
    deadkey_mappings = [
        ("Ãªa", "Ã¢"),
        ("Ãªe", "Å“"),  # Special case: Ãª + e = Å“
        ("Ãªi", "Ã®"),
        ("Ãªo", "Ã´"),
        ("Ãªu", "Ã»"),
        ("Ãªy", "Å·"),
    ]

    # Extract additional mappings from ECirc block if AHK file is provided
    ecirc_mappings = []
    if ahk_file_path:
        try:
            with open(ahk_file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # Extract ECirc block content
            ecirc_content = extract_block_content(content, "ECirc")
            if ecirc_content:
                ecirc_hotstrings = extract_hotstrings(ecirc_content)
                # Flatten all sections into a single list, filtering out uppercase duplicates
                for section_entries in ecirc_hotstrings.values():
                    for (
                        trigger,
                        output,
                        is_word,
                        auto_expand,
                        case_sensitive,
                    ) in section_entries:
                        # Skip uppercase triggers if we already have lowercase equivalent
                        lowercase_trigger = trigger.lower()
                        if trigger != lowercase_trigger and any(
                            existing_trigger == lowercase_trigger
                            for existing_trigger, _ in deadkey_mappings
                        ):
                            continue
                        ecirc_mappings.append(
                            (
                                trigger,
                                output,
                                is_word,
                                auto_expand,
                                case_sensitive,
                            )
                        )

                logger.debug("Found %d ECirc mappings", len(ecirc_mappings))
        except (OSError, ValueError) as e:
            logger.warning("Could not extract ECirc mappings: %s", e)

    header_lines = [
        "# DO NOT EDIT THIS FILE DIRECTLY.",
        "# This file is automatically generated. Any manual changes will be overwritten.",
        "# Format: [[section]]",
        '# All entries use: trigger = { output = "replacement", is_word = true/false, auto_expand = true/false }',
        "",
        "[[e_deadkey]]",
        "# Ãª + vowel = vowel with circumflex accent",
        "# Special case: Ãª + e = Å“",
        "",
    ]

    toml_lines = header_lines.copy()

    # Add basic deadkey mappings
    for trigger, output in deadkey_mappings:
        toml_lines.append(
            f'"{trigger}" = {{ output = "{output}", is_word = false, auto_expand = true }}'
        )

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("\n".join(toml_lines))

    total_mappings = len(deadkey_mappings) + len(ecirc_mappings)
    logger.info(
        "Generated e_deadkey.toml with %d entries (%d deadkey + %d ECirc)",
        total_mappings,
        len(deadkey_mappings),
        len(ecirc_mappings),
    )


def generate_rolls_toml(ahk_file_path: str) -> None:
    """
    Generate rolls.toml file by extracting content from Features["Rolls"] blocks.

    Args:
        ahk_file_path: Path to the source .ahk file
    """
    generation_dir = Path(__file__).parent
    hotstrings_root = generation_dir.parent
    output_dir = hotstrings_root
    output_file = output_dir / "rolls.toml"

    # Read the AutoHotkey file
    try:
        with open(ahk_file_path, "r", encoding="utf-8") as f:
            content = f.read()
    except FileNotFoundError:
        raise FileNotFoundError(f"Source file not found: {ahk_file_path}")
    except OSError as e:
        raise OSError(f"Error reading file {ahk_file_path}: {e}")

    # Find all Features["Rolls"] blocks
    rolls_pattern = r'if Features\["[^"]+"\]\["Rolls"\]\.Enabled\s*\{'
    rolls_matches = list(re.finditer(rolls_pattern, content))

    if not rolls_matches:
        logger.warning('No Features["Rolls"] blocks found in %s', ahk_file_path)
        return

    all_hotstrings: dict[str, list[tuple[str, str, bool, bool]]] = {}

    for match in rolls_matches:
        # Extract block content using brace matching
        start_idx = match.end()
        brace_count = 1
        end_idx = start_idx

        while end_idx < len(content) and brace_count > 0:
            if content[end_idx] == "{":
                brace_count += 1
            elif content[end_idx] == "}":
                brace_count -= 1
            end_idx += 1

        if brace_count == 0:
            block_content = content[start_idx : end_idx - 1]
            hotstrings = extract_hotstrings(block_content)

            # Merge hotstrings from this block
            for section_name, entries in hotstrings.items():
                if section_name not in all_hotstrings:
                    all_hotstrings[section_name] = []
                all_hotstrings[section_name].extend(entries)

    if not all_hotstrings:
        logger.warning('No hotstrings found in Features["Rolls"] blocks')
        return

    # Convert to TOML format
    # Collect descriptions for each Rolls block found
    descriptions: dict[str, str] = {}
    block_name_pattern = r'if Features\["[^\"]+"\]\["([^\"]+)"\]\.?Enabled\s*\{'
    for m in re.finditer(block_name_pattern, content):
        block_name = m.group(1)
        desc = find_description_in_content(content, block_name)
        if desc:
            descriptions[block_name] = desc

    toml_content = convert_to_toml(
        all_hotstrings, "Rolls", descriptions if descriptions else None
    )

    # Write the TOML file
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(toml_content)

    total_entries = sum(len(entries) for entries in all_hotstrings.values())
    logger.info(
        "Generated rolls.toml with %d entries from %d sections",
        total_entries,
        len(all_hotstrings),
    )


def generate_apostrophe_toml(subfolder: str = "") -> None:
    """
    Generate a TOML file for typographic apostrophe hotstrings.

    Args:
        subfolder: Optional subfolder name for organizing output files.
    """
    generation_dir = Path(__file__).parent
    hotstrings_root = generation_dir.parent
    output_dir = hotstrings_root / (subfolder if subfolder else "")
    output_dir.mkdir(exist_ok=True)
    output_file = output_dir / "apostrophe.toml"

    header = TOML_HEADER

    vowels = ["a", "e", "i", "o", "u", "y", "Ã©", "Ãª", "Ã¨"]
    contractions = ["r", "t"]
    chars = vowels + contractions

    hotstrings = []
    for char in chars:
        trigger = f"'{char}"
        output = f"â€™{char}"
        # Escape for TOML
        trigger_escaped = escape_toml_string(trigger)
        output_escaped = escape_toml_string(output)
        hotstrings.append(
            f'"{trigger_escaped}" = {{ output = "{output_escaped}", is_word = false, auto_expand = true }}'
        )

    toml_content = "\n".join(header + ["[[apostrophe]]"] + hotstrings)

    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(toml_content)
        logger.info("Successfully generated apostrophe.toml")
    except OSError as e:
        raise OSError(f"Error writing file {output_file}: {e}")


if __name__ == "__main__":
    main()
